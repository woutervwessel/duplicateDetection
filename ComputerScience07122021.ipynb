{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "ComputerScience07122021.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeFmt0m-WGC5"
      },
      "source": [
        "import pandas as pd\n",
        "import random as rd\n",
        "import json\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "import sympy as sy\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk7Tg44sWGC7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "60a5c6e2-682d-4bb9-d628-216c69ebb2cc"
      },
      "source": [
        "#Opening the .json which is read as a dictionary by python\n",
        "with open('sample_data/TVs-all-merged.json') as f:\n",
        "    data = json.load(f)\n",
        "print(type(data))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-598f9e3d4489>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Opening the .json which is read as a dictionary by python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample_data/TVs-all-merged.json'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sample_data/TVs-all-merged.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6wjpLgfWGC9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e84a7101-1832-406f-99e1-0a2b31e97149"
      },
      "source": [
        "data['UN46ES6580']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'featuresMap': {'ASIN:': 'B007B9PMCO',\n",
              "   'Brand Name': 'Samsung',\n",
              "   'Date first available at Amazon.com': 'February 20, 2012',\n",
              "   'Display Size': '46 inches',\n",
              "   'Display Technology': 'LED-lit',\n",
              "   'Image Aspect Ratio': '16:09',\n",
              "   'Product Dimensions:': '52 x 6.8 x 28.7 inches ; 33.3 pounds',\n",
              "   'Shipping Weight': '41 pounds (',\n",
              "   'Shipping:': 'Currently, item can be shipped only within the U.S.'},\n",
              "  'modelID': 'UN46ES6580',\n",
              "  'shop': 'amazon.com',\n",
              "  'title': 'Samsung UN46ES6580 46-Inch 1080p 120Hz 3D Slim LED HDTV (Black)',\n",
              "  'url': 'http://www.amazon.com/Samsung-UN46ES6580-46-Inch-1080p-120Hz/dp/B007B9PMCO/ref=sr_1_95/182-5884791-9374669?ie=UTF8&qid=1379502010&s=electronics&sr=1-95'},\n",
              " {'featuresMap': {'3DTV': 'Yes',\n",
              "   'Aspect Ratio': '16:9',\n",
              "   'Brand': 'Samsung',\n",
              "   'Cabinet Color': 'Black',\n",
              "   'Component Video': '1 In',\n",
              "   'Composite A/V': '2 In',\n",
              "   'Digital Audio': '1 Optical Out',\n",
              "   'Dimensions With Stand': '42.1\" x 28.3\" x 10.9\" (W x H x D)',\n",
              "   'Dimensions Without Stand': '42.1\" x 25.0\" x 1.2\" (W x H x D)',\n",
              "   'Enhanced Motion': 'Clear Motion Rate 480',\n",
              "   'Feature': 'Smart Content with Signature Services',\n",
              "   'HDMI': '3 In',\n",
              "   'LAN': 'Ethernet x 1',\n",
              "   'LED Technology': 'Edgelit',\n",
              "   'Maximum Resolution': '1920 x 1080',\n",
              "   'Output Power': '10W + 10W',\n",
              "   'Recommended Resolution': '1080p',\n",
              "   'Refresh Rate': '240Hz',\n",
              "   'Screen Size': '46\" Class (45.9\" Diag.)',\n",
              "   'Simulated Surround': 'SRS TheaterSound HD',\n",
              "   'Smart TV': 'Yes',\n",
              "   'Support Video Signal': '1080i/p, 720p, 480i/p',\n",
              "   'USB': '3',\n",
              "   'Weight With Stand': '33.0 lbs.',\n",
              "   'Weight Without Stand': '29.0 lbs.',\n",
              "   'Wireless': 'Wi-Fi Built-in'},\n",
              "  'modelID': 'UN46ES6580',\n",
              "  'shop': 'newegg.com',\n",
              "  'title': 'Newegg.com - Refurbished: Samsung 46\" Class (45.9\" Diag.) 1080p 240Hz LED HDTV UN46ES6580',\n",
              "  'url': 'http://www.newegg.com/Product/Product.aspx?Item=9SIA22F0UT0237'}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Cs20fubWGC-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71a13365-5d54-4e5a-ebeb-9532426d798c"
      },
      "source": [
        "#Looping through the dataset and counting the amount of descriptions per key (Key is model number)\n",
        "amount_of_descriptions = 0\n",
        "for key in data.keys():\n",
        "    amount_of_descriptions += len(data[key])\n",
        "print(amount_of_descriptions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mon-q9EaWGC_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d97a3d0-a0b6-4ac0-83a1-65c5cf023284"
      },
      "source": [
        "#Making the descriptions seperate elements instead of storing them as a single element.\n",
        "#(I think this is preferable for making the algorithm for the paper)\n",
        "new_data = {}\n",
        "i = 1\n",
        "for key in data.keys():\n",
        "    for description in data[key]:\n",
        "        new_data[i] = description\n",
        "        i+=1\n",
        "print(len(new_data.keys()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76LzEKAhWGDA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a35aa5cf-e66c-45e7-bbaa-fe58fa21b6b9"
      },
      "source": [
        "#Check if each product has an element 'shop'\n",
        "shop_elements = 0\n",
        "for key in new_data.keys():\n",
        "    if 'shop' in new_data[key].keys():\n",
        "        shop_elements += 1\n",
        "\n",
        "if shop_elements == len(new_data):\n",
        "    print('True: each product has a shop element')\n",
        "\n",
        "print(shop_elements)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True: each product has a shop element\n",
            "1624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh8TNpXNWGDB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b7b2857-c2c6-4e8c-e7bd-0e1008f6fde0"
      },
      "source": [
        "#Double checking if the claim about their only being maximum of 4 for the same model is true. (it is)\n",
        "highest_amount = 1\n",
        "for key in data.keys():\n",
        "    if len(data[key]) > highest_amount:\n",
        "        highest_amount = len(data[key])\n",
        "print(highest_amount)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkeKmd6PWGDC"
      },
      "source": [
        "#create set of titles \n",
        "def createTitleSet(data):\n",
        "  \"\"\"Returns list of models words from the titles\n",
        "  param: data, dictionary with all product information.\"\"\"\n",
        "\n",
        "  set_titles = {}\n",
        "  for key in data.keys():\n",
        "      set_titles[key] = data[key]['title'] \n",
        "    \n",
        "  #Replace and make seperate elements\n",
        "  regex = '[a-zA-Z0-9.]*[0-9]+[a-zA-Z0-9.]*'\n",
        "  new_title= set_titles.copy()\n",
        "  for key in new_title.keys():\n",
        "      new_title[key] = new_title[key].replace('\"','inch')\n",
        "      new_title[key] = new_title[key].lower()\n",
        "      new_title[key] = re.sub(\"[^a-zA-Z0-9\\s\\.]\",\"\",new_title[key])\n",
        "      new_title[key] = re.findall(regex, new_title[key])\n",
        "    \n",
        "  return new_title"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvouQEtVWGDG"
      },
      "source": [
        "def createBinaryMatrix(data):\n",
        "    \"\"\"\n",
        "    param: data, dictionary, length=|P| \n",
        "    param: set_titles, dictionary, lenght=|P|\n",
        "    Returns binary values, list, shape=(|MW|, |P|)\n",
        "    \"\"\"\n",
        "    \n",
        "    #Create model word list\n",
        "    data_conc = sum(data.values(), [])\n",
        "    MW = sorted(set(data_conc), key=data_conc.index) #extracts unique model words \n",
        "    \n",
        "    #create binary vector \n",
        "    #values are set to 1 if model word is present in title\n",
        "    binary_matrix = np.zeros((len(MW),len(data)),dtype=int)\n",
        "    p=0\n",
        "    for value in data.values():\n",
        "        w=0\n",
        "        for word in MW:\n",
        "            if word in value:\n",
        "                binary_matrix[w,p]=1\n",
        "            w= w+1\n",
        "        p=p+1\n",
        "    return binary_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv0sWUvGlGkl"
      },
      "source": [
        "#MinHash algorithm\n",
        "def createHashValues(lengthBinary, numHashes):\n",
        "  mylist = []\n",
        "  hashval = list(range(1,lengthBinary+1))\n",
        "  hashind = list(range(1,lengthBinary+1))\n",
        "  for i in range(numHashes):\n",
        "    rd.shuffle(hashind)\n",
        "    dicto = dict(zip(hashind,hashval))\n",
        "    mylist.append(dicto)\n",
        "  return mylist\n",
        "  \n",
        "def createSignature(binary_matrix,hashValues,numHashes):\n",
        "  signatures=[]\n",
        "  for product in range(binary_matrix.shape[1]):\n",
        "    sig_val = []\n",
        "    for i in range(numHashes): #N signature values\n",
        "      for hash_val in range(len(binary_matrix)): #Find minHashValue for i-th signature value, goes from 0 to 1299\n",
        "        #print(product,i,hash_val)\n",
        "        index =  hashValues[i].get(hash_val+1) #add 1 to hash value as we go from 1 to 1300 and not 0 to 1299\n",
        "        if (binary_matrix[index-1,product]) == 1:\n",
        "          sig_val.append(hash_val+1)\n",
        "          break\n",
        "    signatures.append(sig_val)\n",
        "  return signatures\n",
        "\n",
        "def minHashing(binary_matrix, numHashes):\n",
        "  hashValues = createHashValues(len(binary_matrix),numHashes)\n",
        "  signatures = createSignature(binary_matrix,hashValues,numHashes)\n",
        "  return signatures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36nGWRurI0fy"
      },
      "source": [
        "#LSH\n",
        "def hashSignaturesToBuckets(data, signatures, b):\n",
        "    \"\"\"\n",
        "    Hashes column bands of each signature to a buckets of that band \n",
        "    : param signatures: array-like, shape=(|P|, n)\n",
        "    returns dictionary with buckets for each band \n",
        "    \"\"\"\n",
        "    n = len(signatures[0])\n",
        "    assert n % b == 0  \n",
        "    r = int(n/b)   #number of rows in each band\n",
        "    product_keys = list(data.keys()) #to get right product key with index\n",
        "    \n",
        "    bucket_bands =[]\n",
        "    for i in range(b): #construct for each band a empty list of buckets \n",
        "        bucket_bands.append({})\n",
        "\n",
        "    buckets=[]\n",
        "    sign_idx=0\n",
        "\n",
        "    #goes trough all product signatures\n",
        "    for signature in signatures: \n",
        "        bands= signatureToBands(signature, r)\n",
        "\n",
        "        #goes trough each band i of a product signature\n",
        "        for i, band in enumerate(bands.astype(str)): \n",
        "            band = ','.join(band)\n",
        "            if band not in bucket_bands[i].keys():\n",
        "                bucket_bands[i][band]=[]\n",
        "            bucket_bands[i][band].append(product_keys[sign_idx])\n",
        "        sign_idx +=1\n",
        "    return bucket_bands\n",
        "\n",
        "\n",
        "def signatureToBands(signature, r):\n",
        "    \"\"\"\n",
        "    Creates bands of length r for each signature vector\n",
        "    : param signature: array-like, shape=(1, |P|)\n",
        "    b: number of bands \n",
        "    returns list of subvectors for signature\n",
        "    \"\"\"\n",
        "    bands=[]\n",
        "    for i in range(0,len(signature), r):#step size r \n",
        "        bands.append(signature[i:i+r])\n",
        "    return np.stack(bands)\n",
        "\n",
        "\n",
        "def candidates(bucket_bands):\n",
        "    \"\"\"\n",
        "    Returns list of candidate neigbors\n",
        "    \"\"\"\n",
        "    candidates = []\n",
        "    for bucket_band in bucket_bands:\n",
        "        for bucket in bucket_band.keys():\n",
        "            products_in_bucket = bucket_band[bucket]\n",
        "            if len(products_in_bucket) > 1:\n",
        "                candidates.extend(combinations(products_in_bucket, 2))\n",
        "    return list(set(candidates)) #returns unique pairs "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEPZgDQbzIBm"
      },
      "source": [
        "def cleanAllLabels(clean_data):\n",
        "    for product in clean_data:\n",
        "        for key in clean_data[product]['featuresMap'].keys():\n",
        "            clean_key = cleanData(key)\n",
        "            clean_data[product]['featuresMap'][clean_key] = clean_data[product]['featuresMap'].pop(key)\n",
        "            clean_data[product]['featuresMap'][clean_key] = cleanData(clean_data[product]['featuresMap'].get(clean_key))\n",
        "            clean_data[product]['title'] = cleanData(clean_data[product]['title'])\n",
        "    return clean_data\n",
        "\n",
        "def cleanData(data):\n",
        "    dataOut = data.replace('\" ','inch')\n",
        "    dataOut = dataOut.replace('\"','inch')\n",
        "    dataOut = dataOut.replace('diag.','diagonal')\n",
        "    dataOut = dataOut.replace('newegg.com','')\n",
        "    dataOut = dataOut.replace('bestbuy','')\n",
        "    dataOut = dataOut.replace('best buy','')\n",
        "    dataOut = dataOut.lower()\n",
        "    dataOut = re.sub(\"[^a-zA-Z0-9\\s\\.]\",\"\",dataOut)\n",
        "    return dataOut\n",
        "\n",
        "from difflib import SequenceMatcher\n",
        "def similarity_score(cleaned_data,new_title,prod1, prod2,w_title,gamma):\n",
        "    w_KVP = 1-w_title\n",
        "    sim = 0\n",
        "    m = 0\n",
        "    w = 0\n",
        "    avgSimKVP = 0\n",
        "\n",
        "    for key1 in cleaned_data[prod1]['featuresMap'].keys():\n",
        "        for key2 in cleaned_data[prod2]['featuresMap'].keys():\n",
        "            keysim = SequenceMatcher(None, key1, key2).ratio()\n",
        "            if keysim > gamma:\n",
        "                valsim = SequenceMatcher(None,cleaned_data[prod1]['featuresMap'][key1],cleaned_data[prod2]['featuresMap'][key2]).ratio()\n",
        "                weight = keysim \n",
        "                sim = sim + weight*valsim\n",
        "                m = m+1\n",
        "                w = w + weight\n",
        "    if w > 0:\n",
        "        avgSimKVP = sim / w\n",
        "        \n",
        "    simTitle = len(list(set(new_title[prod1]).intersection(set(new_title[prod2]))))/len(list(set(new_title[prod1]).union(set(new_title[prod2]))))\n",
        "\n",
        "    similarity_score = w_KVP * avgSimKVP + w_title * simTitle\n",
        "    return similarity_score\n",
        "\n",
        "#True pairs list\n",
        "def findTruePairs(pairs):\n",
        "    true_pairs = []\n",
        "    false_pairs = []\n",
        "    for i in range(len(pairs)):\n",
        "        if new_data[pairs[i][0]]['modelID']==new_data[pairs[i][1]]['modelID']:\n",
        "            true_pairs.append(pairs[i])\n",
        "        else:\n",
        "            false_pairs.append(pairs[i])\n",
        "    return (true_pairs,false_pairs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOC5_h2KzI1n"
      },
      "source": [
        "#CALCULATE SIMILARITIES OF CANDIDATE_PAIRS, RETURN FOUND_PAIRS AS EXPECTED DUPLICATES BASED ON SIMILARITY\n",
        "\n",
        "def MSM(new_data, candidate_pairs, new_title):\n",
        "    #Clean labels as well\n",
        "    cleaned_labels = new_data.copy()\n",
        "    cleaned_labels = cleanAllLabels(cleaned_labels)\n",
        "\n",
        "    #From candidates find true expected duplicates\n",
        "    #Q and GAMMA CAN BE ADJUSTED FOR STRING COMPARISON for better results\n",
        "    w_title = 0.75\n",
        "    gamma = 0.5\n",
        "    sim_tres = 0.35\n",
        "\n",
        "    found_pairs = [];\n",
        "    for i in range(len(candidate_pairs)):\n",
        "        prod1 = candidate_pairs[i][0]\n",
        "        prod2 = candidate_pairs[i][1]\n",
        "        simscore = similarity_score(cleaned_labels,new_title,prod1,prod2,w_title,gamma)\n",
        "        if simscore > sim_tres:\n",
        "            found_pairs.append(candidate_pairs[i])\n",
        "    return found_pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-aDmd0AzIpC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "7f71dd89-bf4e-4c38-a1f1-0d12c03a5e8d"
      },
      "source": [
        "true_pairs, false_pairs = findTruePairs(candidate_pairs)\n",
        "print(len(true_pairs),len(false_pairs))\n",
        "true_pairs, false_pairs = findTruePairs(found_pairs)\n",
        "print(len(true_pairs),len(false_pairs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-64f01f8ac48f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrue_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindTruePairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfalse_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrue_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindTruePairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfalse_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'candidate_pairs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0gfjl4_NI-L"
      },
      "source": [
        "def sampleData(new_data, n_samples):\n",
        "  \"\"\"Samples data\n",
        "  param: new_data, dictionary with all product information, dictionary\n",
        "  param: n_samples, number of samples to draw, integer \n",
        "  \"\"\"\n",
        "  keys = rd.sample(new_data.keys(), n_samples)\n",
        "  sample_d = {k: new_data[k] for k in keys}\n",
        "  return sample_d\n",
        "\n",
        "def truePositive(candidate_pairs):\n",
        "  \"\"\"Return number of true postive pairs\n",
        "  param: candidate_pairs, list of canidates pairs obtained from LSH\"\"\"\n",
        "  TP=0\n",
        "  for candidate_pair in candidate_pairs:\n",
        "    if data[candidate_pair[0]]['modelID']==data[candidate_pair[1]]['modelID']:\n",
        "      TP +=1\n",
        "  return TP\n",
        "\n",
        "def totalAmountDuplicates(data):\n",
        "  \"\"\"Returns number of duplicates in the data\"\"\"\n",
        "  Df=0\n",
        "  modelIDs=[]\n",
        "  for i in range(len(new_data)):\n",
        "      modelIDs.append(new_data[i+1]['modelID'])\n",
        "\n",
        "  rev_dict = {} #dictionary with key: ModelID and value: {indices with that modelID}\n",
        "  for index, modelID in enumerate(modelIDs):\n",
        "      rev_dict.setdefault(modelID, set()).add(index)\n",
        "\n",
        "  duplicates = []\n",
        "  for value in rev_dict.values():\n",
        "    if len(value) > 1:\n",
        "      duplicates.extend(combinations(value, 2))\n",
        "\n",
        "  return len(duplicates), duplicates\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x20SWuCWGhUl"
      },
      "source": [
        "### Perform bootstrap and compute evaluation metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz262y7CpG1s"
      },
      "source": [
        "#bootstraps for LSH performance\n",
        "bootstraps = 1 #5\n",
        "iter = 0\n",
        "\n",
        "n_samples = int(len(new_data)*0.6)\n",
        "\n",
        "n = 540\n",
        "settings =[]\n",
        "for r in range(1,31):\n",
        "  if (n % r) == 0:\n",
        "    b = n/ r\n",
        "    t = (1/b) ** (1/r)\n",
        "    settings.append([t,b,r])\n",
        "\n",
        "settings = settings[10:12] #dit is alleen voor testen\n",
        "\n",
        "all_PQt = np.zeros((1,len(settings)))\n",
        "all_PCt = np.zeros((1,len(settings)))\n",
        "while iter != bootstraps:\n",
        "    #data = sampleData(new_data, n_samples)\n",
        "    #set_titles = createTitleSet(data)\n",
        "    #binary_matrix = createBinaryMatrix(set_titles) \n",
        "    #signatures = minHashing(binary_matrix, n)\n",
        "    \n",
        "    Dn, duplicates  = totalAmountDuplicates(data)\n",
        "    PQ_t  = [] #values for all t for 1 bootstrap\n",
        "    PC_t = []\n",
        "    for setting in settings :\n",
        "        bands =  int(setting[1])\n",
        "        bucket_bands = hashSignaturesToBuckets(data, signatures, bands)\n",
        "        candidate_pairs= candidates(bucket_bands)\n",
        "        found_pairs = MSM(data, candidate_pairs, set_titles)\n",
        "        #print(found_pairs)\n",
        "        Df= truePositive(found_pairs )\n",
        "        Nc = len(found_pairs) #amount of duplicates found\n",
        "\n",
        "        PQ = Df / Nc\n",
        "        PC = Df / Dn\n",
        "\n",
        "        PQ_t.append(PQ)\n",
        "        PC_t.append(PC)\n",
        "    \n",
        "    all_PQt = all_PQt + np.array(PQ_t)\n",
        "    all_PCt = all_PCt + np.array(PC_t)\n",
        "    iter += 1\n",
        "\n",
        "av_PQt =  np.array(all_PQt) / bootstraps\n",
        "av_PCt =  np.array(all_PCt) / bootstraps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deHQKJpAln1P",
        "outputId": "f566de20-547c-4c3d-dbbc-d56b000e7ea5"
      },
      "source": [
        "print(av_PQt )\n",
        "print(av_PCt)\n",
        "print(duplicates) #to do juiste ratio's vinden\n",
        "#komen uit lsh de juiste paren\n",
        "#welke missen? en FP?\n",
        "#wat gebeurd er na MSM welke combi's maken ze dan? zelfde vragen als LSH\n",
        "#F1 score erin zetten\n",
        "#tunen\n",
        "#plotten"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.03827751 0.03030303]]\n",
            "[[0.02005013 0.01002506]]\n",
            "[(9, 10), (12, 13), (16, 15), (19, 20), (26, 27), (29, 30), (32, 31), (36, 37), (44, 45), (48, 49), (48, 50), (49, 50), (52, 53), (56, 55), (61, 62), (65, 66), (68, 69), (73, 74), (75, 76), (77, 78), (80, 79), (86, 87), (89, 90), (92, 93), (94, 95), (110, 111), (113, 114), (117, 118), (120, 119), (133, 134), (136, 135), (140, 141), (146, 147), (150, 151), (156, 157), (160, 161), (160, 162), (161, 162), (163, 164), (168, 167), (171, 172), (184, 183), (188, 189), (192, 193), (194, 195), (197, 198), (201, 202), (206, 207), (211, 212), (222, 223), (224, 225), (230, 231), (232, 233), (236, 237), (236, 238), (237, 238), (242, 243), (250, 251), (252, 253), (266, 267), (272, 273), (272, 271), (273, 271), (276, 277), (276, 278), (277, 278), (280, 281), (282, 283), (285, 286), (285, 287), (286, 287), (288, 289), (296, 295), (299, 300), (307, 308), (309, 310), (316, 317), (324, 325), (326, 327), (329, 330), (329, 331), (330, 331), (337, 338), (344, 345), (350, 351), (355, 356), (370, 371), (376, 377), (380, 381), (388, 389), (396, 397), (398, 399), (404, 405), (408, 409), (416, 415), (418, 419), (425, 426), (427, 428), (436, 437), (445, 446), (449, 450), (453, 454), (457, 458), (465, 466), (480, 479), (481, 482), (481, 483), (482, 483), (485, 486), (485, 487), (486, 487), (496, 495), (502, 503), (504, 505), (507, 508), (520, 521), (522, 523), (524, 525), (528, 527), (532, 533), (534, 535), (541, 542), (544, 545), (555, 556), (560, 561), (570, 571), (573, 574), (577, 578), (579, 580), (582, 583), (584, 585), (587, 588), (593, 594), (595, 596), (597, 598), (604, 605), (608, 607), (617, 618), (624, 625), (626, 627), (632, 633), (634, 635), (638, 639), (651, 652), (653, 654), (656, 655), (657, 658), (664, 665), (672, 671), (676, 677), (680, 679), (684, 685), (691, 692), (693, 694), (702, 703), (705, 706), (710, 711), (715, 716), (720, 718), (720, 719), (718, 719), (726, 727), (731, 732), (736, 737), (739, 740), (744, 745), (748, 749), (754, 755), (757, 758), (760, 759), (784, 785), (790, 791), (796, 797), (800, 799), (805, 806), (809, 810), (813, 814), (817, 818), (817, 819), (818, 819), (824, 825), (833, 834), (836, 837), (838, 839), (840, 841), (842, 843), (849, 850), (856, 855), (865, 866), (868, 869), (880, 879), (886, 887), (889, 890), (891, 892), (896, 895), (901, 902), (904, 905), (904, 903), (905, 903), (906, 907), (912, 911), (921, 922), (923, 924), (945, 946), (949, 950), (949, 951), (950, 951), (954, 955), (956, 957), (960, 959), (961, 962), (963, 964), (966, 967), (979, 980), (981, 982), (985, 986), (988, 989), (992, 991), (993, 994), (1000, 999), (1001, 1002), (1006, 1007), (1010, 1011), (1016, 1017), (1016, 1018), (1017, 1018), (1021, 1022), (1026, 1027), (1034, 1035), (1042, 1043), (1044, 1045), (1049, 1050), (1049, 1051), (1049, 1052), (1050, 1051), (1050, 1052), (1051, 1052), (1056, 1057), (1056, 1055), (1057, 1055), (1059, 1060), (1064, 1063), (1067, 1068), (1072, 1073), (1074, 1075), (1077, 1078), (1080, 1081), (1082, 1083), (1082, 1084), (1083, 1084), (1085, 1086), (1090, 1091), (1092, 1093), (1092, 1094), (1093, 1094), (1097, 1098), (1099, 1100), (1101, 1102), (1105, 1106), (1107, 1108), (1112, 1111), (1117, 1118), (1120, 1119), (1122, 1123), (1126, 1127), (1128, 1129), (1132, 1133), (1134, 1135), (1141, 1142), (1144, 1143), (1166, 1167), (1169, 1170), (1176, 1177), (1179, 1180), (1184, 1183), (1185, 1186), (1187, 1188), (1197, 1198), (1197, 1199), (1198, 1199), (1200, 1201), (1203, 1204), (1213, 1214), (1216, 1217), (1218, 1219), (1232, 1231), (1234, 1235), (1240, 1241), (1240, 1242), (1240, 1243), (1241, 1242), (1241, 1243), (1242, 1243), (1248, 1245), (1248, 1246), (1248, 1247), (1245, 1246), (1245, 1247), (1246, 1247), (1250, 1251), (1264, 1265), (1266, 1267), (1272, 1273), (1272, 1274), (1273, 1274), (1278, 1279), (1288, 1286), (1288, 1287), (1286, 1287), (1292, 1293), (1296, 1295), (1304, 1305), (1304, 1306), (1305, 1306), (1310, 1311), (1312, 1313), (1317, 1318), (1320, 1319), (1321, 1322), (1326, 1327), (1328, 1329), (1334, 1335), (1339, 1340), (1341, 1342), (1344, 1345), (1347, 1348), (1349, 1350), (1353, 1354), (1356, 1357), (1358, 1359), (1363, 1364), (1368, 1367), (1369, 1370), (1372, 1373), (1372, 1374), (1373, 1374), (1376, 1377), (1380, 1381), (1390, 1391), (1393, 1394), (1396, 1397), (1400, 1399), (1405, 1406), (1408, 1407), (1424, 1423), (1426, 1427), (1432, 1431), (1437, 1438), (1440, 1439), (1444, 1445), (1452, 1453), (1456, 1455), (1458, 1459), (1461, 1462), (1467, 1468), (1472, 1469), (1472, 1470), (1472, 1471), (1469, 1470), (1469, 1471), (1470, 1471), (1477, 1478), (1481, 1482), (1485, 1486), (1485, 1487), (1486, 1487), (1490, 1491), (1502, 1503), (1504, 1505), (1512, 1511), (1517, 1518), (1522, 1523), (1524, 1525), (1530, 1531), (1532, 1533), (1541, 1542), (1544, 1543), (1545, 1546), (1549, 1550), (1557, 1558), (1560, 1559), (1563, 1564), (1563, 1565), (1564, 1565), (1568, 1567), (1573, 1574), (1576, 1575), (1579, 1580), (1587, 1588), (1587, 1589), (1588, 1589), (1592, 1591), (1595, 1596), (1601, 1602), (1603, 1604), (1608, 1607), (1610, 1611), (1614, 1615), (1620, 1621)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3J9w2EF7mkTR",
        "outputId": "f66fe1e1-3a10-424a-9b98-d42f01d56fb8"
      },
      "source": [
        "settings = settings[10:12] #dit is alleen voor testen\n",
        "settings = [1,2,3,4]\n",
        "all_PQt = np.zeros((1, len(settings)))\n",
        "\n",
        "all_PQt + np.array(settings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 2., 3., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "XfqZogkmIHdM",
        "outputId": "74ecdd36-32e0-4c2e-c59a-539cac53188d"
      },
      "source": [
        "cleaned_labels = data.copy()\n",
        "cleaned_labels = cleanAllLabels(cleaned_labels)\n",
        "cleaned_labels.index(342)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-571b9bdaac46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcleaned_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcleaned_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleanAllLabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcleaned_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m342\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'index'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbsylAgTjBIM",
        "outputId": "ecf9e0ce-e9c4-4d7b-a549-c594a4c131ce"
      },
      "source": [
        "max =0\n",
        "n=1000\n",
        "while n != 0:\n",
        "  n_samples = int(len(new_data)*0.6)\n",
        "  data = sampleData(new_data, n_samples)\n",
        "  set_titles = createTitleSet(data)\n",
        "  binary_matrix = createBinaryMatrix(set_titles)\n",
        "\n",
        "  if max < len(binary_matrix):\n",
        "    max = len(binary_matrix)\n",
        "  n -=1\n",
        "\n",
        "print(max)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_p9DWA_2jGYl"
      },
      "source": [
        "signatures = minHashing(binary_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_t1zpHjwjL4u",
        "outputId": "43547e4d-a03d-4a7f-ecbc-12cca038f674"
      },
      "source": [
        "print(len(new_data))\n",
        "print(len(binary_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1624\n",
            "974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIR0vBW3msJd"
      },
      "source": [
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAIQXv1CkM0e",
        "outputId": "d366ef27-fbd2-45ad-f84f-9a44cee548bb"
      },
      "source": [
        "n= 800\n",
        "b = 400\n",
        "r = n/b\n",
        "print(r)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKD8SEmzpPOn"
      },
      "source": [
        "t = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RW-zIHjmg5nJ",
        "outputId": "dac54fe8-46f8-4818-c367-6bcb0e80459a"
      },
      "source": [
        "numHashes = round(0.5*(len(binary_matrix)+0.5))\n",
        "numHashes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "441"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf0-Or8JKesI",
        "outputId": "009796d0-b31b-4dec-b070-887a601336e1"
      },
      "source": [
        "ini_dict = {1: 'LC-90LE657U',\n",
        " 2: 'LC-90LE657U',\n",
        " 3: '39PFL2908/F7',\n",
        " 4: 'LC70LE550U',\n",
        " 5: 'UN40F6350A',\n",
        " 6: 'UN40F6350A', \n",
        " 7: 'UN40F6350A'}\n",
        "\n",
        "# finding duplicate values\n",
        "# from dictionary\n",
        "# using a naive approach\n",
        "rev_dict = {}\n",
        "  \n",
        "for index, product in ini_dict.items():\n",
        "    rev_dict.setdefault(product, set()).add(index)\n",
        "\n",
        "print(rev_dict)\n",
        "duplicates = []\n",
        "for value in rev_dict.values():\n",
        "  if len(value) > 1:\n",
        "    duplicates.extend(combinations(value, 2))\n",
        "Df = len(duplicates)\n",
        "print(Df)\n",
        "    #Df += len(combinations(values, 2))\n",
        "\n",
        "print(duplicates)\n",
        "#result = [(key, values) for key, values in rev_dict.items() if len(values) > 1]\n",
        "#result2 = \n",
        "  \n",
        "# printing result\n",
        "#print(result)\n",
        "#print(result2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'LC-90LE657U': {1, 2}, '39PFL2908/F7': {3}, 'LC70LE550U': {4}, 'UN40F6350A': {5, 6, 7}}\n",
            "4\n",
            "[(1, 2), (5, 6), (5, 7), (6, 7)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyK3yx6llVaL"
      },
      "source": [
        "def generateRandomNumbers(n):\n",
        "    \"\"\"Returns a list of n random numbers\"\"\"\n",
        "    randList = []\n",
        "\n",
        "    while n > 0:\n",
        "        # Get a random model word index\n",
        "        randIndex = random.randint(0, len(MW)) \n",
        "  \n",
        "        # Ensure that each random number is unique.\n",
        "        while randIndex in randList:\n",
        "            randIndex = random.randint(0, len(MW)) \n",
        "        # Add the random number to the list.\n",
        "        randList.append(randIndex)\n",
        "        n = n - 1\n",
        "    return randList"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FbUhvyJWGDH"
      },
      "source": [
        "#OLD VERSION OF MINHASHING\n",
        "def minHashing(binary_matrix):\n",
        "    \"\"\"Hashes binary matrix to a signature matrix\n",
        "    param: binary_matrix: binary values sorted by product, array-like, shape=(|MW|, |P|)\n",
        "    param: prime: prime number\n",
        "    returns signatures, list with dimensions (|P|, n)\n",
        "    \"\"\"\n",
        "    n = int(0.5 * len(binary_matrix)) # number of hash functions=1/2*\\MW|\n",
        "    coeffA= generateRandomNumbers(n)\n",
        "    coeffB= generateRandomNumbers(n)\n",
        "    prime = sy.nextprime(len(binary_matrix))\n",
        "   \n",
        "    \n",
        "    signatures=[]\n",
        "    # For each product in binary_matrix create n signatures  \n",
        "    for product in range(binary_matrix.shape[1]):\n",
        "        signature = []\n",
        "        # For each of the permutation\n",
        "        for i in range(n):\n",
        "            hashCode = (coeffA[i] * product + coeffB[i]) % prime\n",
        "\n",
        "            # Initialize 'minHashCode' to be greater than the maximum possible value output by the hash.\n",
        "            minHashCode = prime\n",
        "            #Determine smallest hash code value \n",
        "            for word in range(binary_matrix.shape[0]):\n",
        "                if binary_matrix[word,product]==1:\n",
        "                    if hashCode <= minHashCode:\n",
        "                        minHashCode = hashCode \n",
        "\n",
        "            # Add smallest hash code value for hash function 'i' to the signature of product.\n",
        "            signature.append(minHashCode)\n",
        "\n",
        "        # Store the MinHash signature for each permutation.\n",
        "        signatures.append(signature)\n",
        "    return signatures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOcCUgmTsBDL"
      },
      "source": [
        "test_binary_matrix = np.array([[0, 0, 0, 1], [1, 0, 0, 1], [0, 1, 0, 1],[1, 0, 1, 1],[1, 0, 1, 1],[1, 0, 1, 1]])\n",
        "test_binary_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlsTq0blsHRB"
      },
      "source": [
        "hashValues = createHashValues(len(test_binary_matrix),20)\n",
        "hashValues\n",
        "\n",
        "binary_matrix = np.array([[1,1,1],[0,1,1],[1,0,0],[0,0,1]])\n",
        "print(binary_matrix)\n",
        "n = 3\n",
        "hashValues = createHashValues(binary_matrix,n)\n",
        "print(hashValues)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJApkAZ2WGDI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "87e58e0a-6d92-4002-89be-1c6ed226f0ab"
      },
      "source": [
        "binary_matrix= create_binary_matrix(new_title)\n",
        "print(binary_matrix.shape)\n",
        "print(np.max(np.sum(binary_matrix, axis=0))) #gek want een zin bestaat vgm niet uit         \n",
        "#print(binary_matrix.shape)\n",
        "#signatures=minHashing(binary_matrix, 947)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1300, 1624)\n",
            "8.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-158-a603762ff592>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#gek want een zin bestaat vgm niet uit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#print(binary_matrix.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msignatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminHashing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m947\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-156-c895437cfc13>\u001b[0m in \u001b[0;36mminHashing\u001b[0;34m(binary_matrix, prime)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mminHashCode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprime\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m#Determine smallest hash code value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbinary_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhashCode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mminHashCode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUqLhX3gWGDK",
        "outputId": "4108bfd9-78fb-4bb7-846f-24a4048f4c66"
      },
      "source": [
        "sign0 = [6,7,8,10,1,3,4,5, 1, 2,3,4]\n",
        "sign1 = [1,3,4,5,7,7,8,10, 0, 2,3,4]\n",
        "sign2 = [1,3,4,5,7,7,8,10, 1, 2,3,4]\n",
        "sign3 = [1,3,4,5,7,7,8,10, 1, 2,3,1]\n",
        "sign4 = [1,3,4,5,7,7,8,10, 1, 2,3,4]\n",
        "\n",
        "\n",
        "signatures= np.array([sign0, sign1, sign2, sign3, sign4])\n",
        "\n",
        "buckets= has_to_buckets(2,signatures)\n",
        "\n",
        "print(buckets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'6,7,8,10,1,3': [0], '1,3,4,5,7,7': [1, 2, 3, 4]}, {'4,5,1,2,3,4': [0], '8,10,0,2,3,4': [1], '8,10,1,2,3,4': [2, 4], '8,10,1,2,3,1': [3]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSvCCSPiRrWb",
        "outputId": "242cecc3-81d9-41d1-a406-a4a7862c913c"
      },
      "source": [
        "#OLD CODE FOR CLUSTERING\n",
        "\n",
        "def create_upper_matrix(values, size):\n",
        "    upper = np.zeros((size, size))\n",
        "    upper[np.triu_indices(size, 0)] = values\n",
        "    return(upper)\n",
        "\n",
        "c = create_upper_matrix([x for x in range(1,15+1)], 5)\n",
        "cd = c - np.identity(len(c)) * c\n",
        "cd[3,4] = 10**99\n",
        "cd[0,1] = 0.0\n",
        "print(cd)\n",
        "\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "cluster = linkage(cd, method='single', metric='euclidean', optimal_ordering=False)\n",
        "cluster\n",
        "\n",
        "#creating clusters\n",
        "aggl = AgglomerativeClustering(n_clusters=3).fit_predict(cd)\n",
        "print(aggl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0e+00 0.0e+00 3.0e+00 4.0e+00 5.0e+00]\n",
            " [0.0e+00 0.0e+00 7.0e+00 8.0e+00 9.0e+00]\n",
            " [0.0e+00 0.0e+00 0.0e+00 1.1e+01 1.2e+01]\n",
            " [0.0e+00 0.0e+00 0.0e+00 0.0e+00 1.0e+99]\n",
            " [0.0e+00 0.0e+00 0.0e+00 0.0e+00 0.0e+00]]\n"
          ]
        }
      ]
    }
  ]
}